{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Dropout\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "boston_df = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "boston_df['y'] = boston['target']\n",
    "\n",
    "x_cols = boston['feature_names']\n",
    "\n",
    "print(boston['DESCR'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data intro train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(boston_df, test_size=0.2)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "valid_df = valid_df.copy()\n",
    "\n",
    "print('#train:', len(train_df), '#valid:', len(valid_df), '#test:', len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaller = StandardScaler()\n",
    "\n",
    "train_df[x_cols] = scaller.fit_transform(train_df[x_cols])\n",
    "test_df[x_cols] = scaller.transform(test_df[x_cols])\n",
    "valid_df[x_cols] = scaller.transform(valid_df[x_cols])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's back to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df[x_cols].values, train_df['y'].values\n",
    "X_test, y_test = test_df[x_cols].values, test_df['y'].values\n",
    "X_valid, y_valid = valid_df[x_cols].values, valid_df['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(len(x_cols), input_dim=len(x_cols), kernel_initializer='normal', activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.compile('adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, epochs=600, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('R^2:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excersize: try to overfit modifying NN structure (add layers, make them wider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excersize: explore history object and plot training history (aka learning curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use callbacks\n",
    "\n",
    "Keras contains a callback mechanism allows to call your own function after each epoch, before each epoch, after each batch, etc.\n",
    "\n",
    "Also Keras includes a bunch of predefined callbacks, for example for checkpining, early stopping, learning rate decay..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(len(x_cols), input_dim=len(x_cols), kernel_initializer='normal', activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal')\n",
    "])\n",
    "\n",
    "model.compile('adam', loss='mean_squared_error')\n",
    "\n",
    "# set up callbacks\n",
    "!rm -rf /tmp/checkpoints\n",
    "!mkdir /tmp/checkpoints\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "logger = CSVLogger('/tmp/log.csv')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=1000,\n",
    "                    callbacks=[checkpointer, logger],\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('R^2:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston_df[x_cols].values, boston_df['y'].values\n",
    "\n",
    "\n",
    "def build_fn():\n",
    "    model = Sequential([\n",
    "        Dense(len(x_cols), input_dim=len(x_cols), kernel_initializer='normal', activation='relu'),\n",
    "        Dense(1, kernel_initializer='normal')\n",
    "    ])\n",
    "    \n",
    "    model.compile('adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('mlp', KerasRegressor(build_fn=build_fn, epochs=300, batch_size=16, verbose=0))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5, random_state=1234)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold, scoring='r2', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2:', results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excersize: play with NN structure. Try a deepper network and a wider ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
